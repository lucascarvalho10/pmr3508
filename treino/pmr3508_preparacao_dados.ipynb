{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparação de Dados"
      ],
      "metadata": {
        "id": "NOfa9fE_eAHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A ideia central deste notebook é conseguir aplicar alguns conceitos de pereação de dados vistos em aula.\n",
        "\n"
      ],
      "metadata": {
        "id": "ambkaqPzeH1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as plt"
      ],
      "metadata": {
        "id": "uW6e7_FzeGf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-Hot Encoding"
      ],
      "metadata": {
        "id": "xvGHaReEeYNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "De forma simplificada, é conseguir compilar dados categóricos em uma representação mais simples, como binário ou inteiro."
      ],
      "metadata": {
        "id": "5pcQgsa5fBs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dados\n",
        "data = {'Cor': ['Vermelho', 'Azuk', 'Verde', 'Azul', 'Vermelho']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# one-hot encoding\n",
        "one_hot_encoded_df = pd.get_dummies(df, columns=['Cor'])\n",
        "\n",
        "print(one_hot_encoded_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi9sO3cme5Tx",
        "outputId": "9e5c190b-5a48-46d2-d729-cf6b0d984afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Cor_Azuk  Cor_Azul  Cor_Verde  Cor_Vermelho\n",
            "0     False     False      False          True\n",
            "1      True     False      False         False\n",
            "2     False     False       True         False\n",
            "3     False      True      False         False\n",
            "4     False     False      False          True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`df_one_hot = pd.get_dummies(df, columns=['Cor']):` Utilizamos a função get_dummies do pandas para realizar o one-hot encoding na coluna Cor. Isso cria novas colunas para cada valor único em Cor ('Vermelho', 'Azul', 'Verde').\n"
      ],
      "metadata": {
        "id": "tgT7DD2wfhdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detecção de Outliers"
      ],
      "metadata": {
        "id": "8gYEUKN9fz5v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detectar outliers é um passo importante na análise de dados, pois eles podem distorcer os resultados de modelos de machine learning. Um método comum para detectar outliers é o uso do IQR (Interquartile Range). Vou mostrar um exemplo de como fazer isso em Python."
      ],
      "metadata": {
        "id": "AfS1T_5wf--h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando um DataFrame de exemplo\n",
        "data = {'Valores': [10, 12, 14, 16, 18, 20, 100, 25, 30, 35, 40]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculando o IQR\n",
        "Q1 = df['Valores'].quantile(0.25)  # Primeiro quartil (25%)\n",
        "Q3 = df['Valores'].quantile(0.75)  # Terceiro quartil (75%)\n",
        "IQR = Q3 - Q1  # Intervalo interquartil\n",
        "\n",
        "# Definindo os limites\n",
        "limite_inferior = Q1 - 1.5 * IQR\n",
        "limite_superior = Q3 + 1.5 * IQR\n",
        "\n",
        "# Detectando outliers\n",
        "outliers = df[(df['Valores'] < limite_inferior) | (df['Valores'] > limite_superior)]\n",
        "\n",
        "# Exibindo os outliers\n",
        "print(\"Outliers detectados:\")\n",
        "print(outliers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3IJClDnfzVU",
        "outputId": "e26e1cd7-096d-4b10-ad69-1e1aa4f0f67e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outliers detectados:\n",
            "   Valores\n",
            "6      100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Undersampling e Oversampling"
      ],
      "metadata": {
        "id": "319XBXQRgUJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quando lidamos com problemas de classificação em que as classes estão desbalanceadas, técnicas como oversampling (superamostragem) e undersampling (subamostragem) são frequentemente usadas para equilibrar a distribuição das classes. Vou mostrar como implementar ambas as técnicas em Python usando a biblioteca imbalanced-learn.\n",
        "\n"
      ],
      "metadata": {
        "id": "NR2pAaJOggJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U imbalanced-learn --quiet"
      ],
      "metadata": {
        "id": "KtXcM9pbgg8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "0MNAdyZggqji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerando um dataset desbalanceado de exemplo\n",
        "X, y = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0,\n",
        "                           n_clusters_per_class=1, weights=[0.9, 0.1], flip_y=0, random_state=1)\n",
        "\n",
        "# Convertendo para DataFrame para melhor visualização\n",
        "df = pd.DataFrame(X, columns=['Feature1', 'Feature2'])\n",
        "df['Classe'] = y\n",
        "\n",
        "# Exibindo a distribuição original\n",
        "print(\"Distribuição Original das Classes:\")\n",
        "print(df['Classe'].value_counts())\n",
        "\n",
        "# Oversampling (Aumentando a Classe Minoritária)\n",
        "ros = RandomOverSampler(random_state=1)\n",
        "X_res, y_res = ros.fit_resample(X, y)\n",
        "\n",
        "# Convertendo para DataFrame para melhor visualização\n",
        "df_res = pd.DataFrame(X_res, columns=['Feature1', 'Feature2'])\n",
        "df_res['Classe'] = y_res\n",
        "\n",
        "print(\"\\nDistribuição das Classes Após Oversampling:\")\n",
        "print(df_res['Classe'].value_counts())\n",
        "\n",
        "# Undersampling (Reduzindo a Classe Majoritária)\n",
        "rus = RandomUnderSampler(random_state=1)\n",
        "X_res_under, y_res_under = rus.fit_resample(X, y)\n",
        "\n",
        "# Convertendo para DataFrame para melhor visualização\n",
        "df_res_under = pd.DataFrame(X_res_under, columns=['Feature1', 'Feature2'])\n",
        "df_res_under['Classe'] = y_res_under\n",
        "\n",
        "print(\"\\nDistribuição das Classes Após Undersampling:\")\n",
        "print(df_res_under['Classe'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Hsmz5PsguW0",
        "outputId": "0e563095-9d8f-407f-a22a-5697e97e0ea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribuição Original das Classes:\n",
            "Classe\n",
            "0    900\n",
            "1    100\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribuição das Classes Após Oversampling:\n",
            "Classe\n",
            "0    900\n",
            "1    900\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribuição das Classes Após Undersampling:\n",
            "Classe\n",
            "0    100\n",
            "1    100\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SMOTE"
      ],
      "metadata": {
        "id": "9dmIfiW8g88o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Além de oversampling e undersampling, existem outras técnicas interessantes para lidar com o desbalanceamento de classes. Uma técnica que merece destaque é o SMOTE (Synthetic Minority Over-sampling Technique), que é uma variação do oversampling. Ao invés de simplesmente duplicar exemplos da classe minoritária, o SMOTE gera novos exemplos sintéticos, criando um conjunto de dados mais diversificado."
      ],
      "metadata": {
        "id": "r961FnvAg-L1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerando um dataset desbalanceado de exemplo\n",
        "X, y = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0,\n",
        "                           n_clusters_per_class=1, weights=[0.9, 0.1], flip_y=0, random_state=1)\n",
        "\n",
        "# Convertendo para DataFrame para melhor visualização\n",
        "df = pd.DataFrame(X, columns=['Feature1', 'Feature2'])\n",
        "df['Classe'] = y\n",
        "\n",
        "# Exibindo a distribuição original\n",
        "print(\"Distribuição Original das Classes:\")\n",
        "print(df['Classe'].value_counts())\n",
        "\n",
        "# Aplicando SMOTE\n",
        "smote = SMOTE(random_state=1)\n",
        "X_smote, y_smote = smote.fit_resample(X, y)\n",
        "\n",
        "# Convertendo para DataFrame para melhor visualização\n",
        "df_smote = pd.DataFrame(X_smote, columns=['Feature1', 'Feature2'])\n",
        "df_smote['Classe'] = y_smote\n",
        "\n",
        "print(\"\\nDistribuição das Classes Após SMOTE:\")\n",
        "print(df_smote['Classe'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owlCKB_5hBWf",
        "outputId": "c70692ad-6af9-4094-af21-5bf85c9218a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribuição Original das Classes:\n",
            "Classe\n",
            "0    900\n",
            "1    100\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribuição das Classes Após SMOTE:\n",
            "Classe\n",
            "0    900\n",
            "1    900\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}