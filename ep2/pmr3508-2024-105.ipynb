{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWRYxjUJBYJQ"
   },
   "source": [
    "# **PMR3508 - Aprendizado de Máquina e Reconhecimento de Padrões (2024)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4S7_SY2jD7xf"
   },
   "source": [
    "## *Segundo Exercício Programa - ANN para o Dataset MNIST*\n",
    "\n",
    "**Nome**: Lucas Carvalho\n",
    "\n",
    "**NUSP**: 11850649\n",
    "\n",
    "**Hash**: 105"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lG-GjK2KD_rv"
   },
   "source": [
    "## *Descrição:*\n",
    "\n",
    "Neste exercício, você irá trabalhar com o **dataset MNIST**, um conjunto de dados com 70.000 imagens de dígitos escritos à mão. Seu objetivo será aplicar os conceitos de **Redes Neurais Artificiais (ANNs)** vistos na aula teórica. Este EP está dividido em tarefas, sua formatação não deve ser alterada, mas novas células de código ou texto podem ser criadas nos blocos de cada tarefa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambiente de Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UNlw6PcAtIW"
   },
   "source": [
    "## Loading dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Up-QY3yPcITN"
   },
   "outputs": [],
   "source": [
    "# Configuração de seeds para replicabilidade\n",
    "np.random.seed(42)  # Seed para NumPy\n",
    "random.seed(42)     # Seed para o módulo random\n",
    "\n",
    "# input_path = \"/kaggle/input/pmr3508-mnist\"  # Obtém o diretório atual\n",
    "\n",
    "input_path = os.getcwd()  # Obtém o diretório atual\n",
    "images_filepath = join(input_path, 'MNIST-images.pkl')\n",
    "labels_filepath = join(input_path, 'MNIST-labels.pkl')\n",
    "validation_images_filepath = join(input_path, 'MNIST-validation-images.pkl')\n",
    "\n",
    "with open(images_filepath, 'rb') as f:\n",
    "    X_tot = pickle.load(f)\n",
    "\n",
    "with open(labels_filepath, 'rb') as f:\n",
    "    y_tot = pickle.load(f)\n",
    "\n",
    "with open(validation_images_filepath, 'rb') as f:\n",
    "    X_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 910
    },
    "id": "Oj8ARMguedYL",
    "outputId": "86d3a6f6-94a2-4056-cd53-e95cc800867c"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TESTE DE CARREGAMENTO DO DATASET POR VISUALIZAÇÃO\n",
    "Este bloco visualiza algumas imagens do dataset MNIST para verificar se o\n",
    "carregamento foi realizado corretamente.\n",
    "'''\n",
    "\n",
    "def show_images(images, title_texts):\n",
    "    # Função para mostrar as imagens com seus respectivos títulos\n",
    "    cols = 3  # Número de colunas na visualização\n",
    "    rows = int(len(images) / cols) + 1  # Calcula o número de linhas\n",
    "    plt.figure(figsize=(12, 12))  # Define o tamanho da figura\n",
    "    index = 1\n",
    "    for x in zip(images, title_texts):  # Itera sobre as imagens e títulos\n",
    "        image = x[0]\n",
    "        title_text = x[1]\n",
    "        plt.subplot(rows, cols, index)  # Adiciona um subplot\n",
    "        plt.axis('off')  # Desativa os eixos\n",
    "        plt.imshow(image, cmap=plt.cm.gray)  # Mostra a imagem em escala de cinza\n",
    "        if (title_text != ''):\n",
    "            plt.title(title_text, fontsize=15)  # Define o título da imagem\n",
    "        index += 1\n",
    "    plt.tight_layout()  # Ajusta o layout para evitar sobreposição de títulos\n",
    "    plt.show()  # Exibe a figura com as imagens e títulos\n",
    "\n",
    "images_2_show = []  # Lista para armazenar as imagens a serem mostradas\n",
    "titles_2_show = []  # Lista para armazenar os títulos das imagens\n",
    "# Seleciona aleatoriamente 9 imagens de treino\n",
    "for i in range(0, 9):\n",
    "    r = random.randint(1, 60000)\n",
    "    images_2_show.append(X_tot[r])  # Adiciona a imagem selecionada à lista\n",
    "    titles_2_show.append(f\"Imagem [{str(r)}] = {str(y_tot[r])}\")  # Adiciona o título correspondente\n",
    "\n",
    "show_images(images_2_show, titles_2_show)  # Exibe as imagens selecionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqDjIWMMKrwp"
   },
   "source": [
    "# Tarefa 01: Probabilidades "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGh3ahlqLwZO"
   },
   "source": [
    "### Item a)\n",
    "\n",
    "Descubra o número do Dataset associado ao seu Hash.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fc4i-5drRtQo"
   },
   "outputs": [],
   "source": [
    "y_tot[105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Apresentando a imagem visualmente:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))  \n",
    "plt.imshow(X_tot[105], cmap='gray')  \n",
    "plt.axis('off')  \n",
    "plt.title(f\"Dígito {y_tot[105]}\", fontsize=15)  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhFiXcpKRVMA"
   },
   "source": [
    "### Item b)\n",
    "\n",
    "Determine, para a imagem vinculada ao seu Hash, qual é a Probabilidade de um píxel claro (128 - 225) para esta única imagem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYQId5z6RskB"
   },
   "outputs": [],
   "source": [
    "light_pixel = 0\n",
    "total = 0\n",
    "\n",
    "for row in X_tot[105]:\n",
    "    for pixel in row:\n",
    "        total += 1\n",
    "        if pixel >= 128 and pixel <= 225: light_pixel += 1\n",
    "        \n",
    "f\"{100*light_pixel/total} %\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Na imagem vinculada, existe uma proababilidade de 1,14% de o pixel ser branco*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7I1XtkhRuTH"
   },
   "source": [
    "### Item c)\n",
    "\n",
    "Qual é a probabilidade de um píxel ser claro dentre todos os píxeis que tem a mesma classe que a sua imagem obtida em a)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-d8EXgbStF1"
   },
   "outputs": [],
   "source": [
    "light_pixel = 0\n",
    "total = 0\n",
    "\n",
    "for i in range(len(X_tot)):\n",
    "    if y_tot[i] == 1:\n",
    "        for row in X_tot[i]:\n",
    "            for pixel in row:\n",
    "                total += 1\n",
    "                if pixel >= 128 and pixel <= 225: light_pixel += 1\n",
    "                \n",
    "f\"{100*light_pixel/total} %\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Existe uma proabilidade de 2,237% de, dentre todos os \"1\"s, existir um pixel branco dentre os pixels da imagem. Considerando que o valor obtido para a imagem referente ao Hash é relativamente próxima, é um resultado adequado, considerando o valor esperado.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a8k73BRHMJE"
   },
   "source": [
    "# Tarefa 02: Análise Exploratória de Dados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxW_LjGSJBk4"
   },
   "source": [
    "### Item a)\n",
    "\n",
    "Conte quantas vezes cada dígito (de 0 a 9) aparece e responda:\n",
    "\n",
    "1. Todos os dígitos aparecem a mesma quantidade?\n",
    "\n",
    "*Não, embora sejam valores relativamente próximos, não é a mesma frequência, embora o valor médio de ocorrências seja, com efeito, 6000*\n",
    "\n",
    "2. Qual o valor médio dos píxeis de cada dígito?\n",
    "\n",
    "*Estão indicados abaixo, para cada um dos dígitos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7nOhtKqJUj0"
   },
   "outputs": [],
   "source": [
    "count_dict = Counter(y_tot)\n",
    "\n",
    "total_count = 0\n",
    "pixel_sums_by_digit = {i: 0 for i in range(10)}  \n",
    "pixel_counts_by_digit = {i: 0 for i in range(10)}  \n",
    "\n",
    "for img, label in zip(X_tot, y_tot):\n",
    "    flattened_img = img.flatten()  \n",
    "    pixel_sums_by_digit[label] += np.sum(flattened_img)\n",
    "    pixel_counts_by_digit[label] += len(flattened_img)\n",
    "\n",
    "print(\"Contagem e valor médio de pixels por dígito:\")\n",
    "for number in range(10):\n",
    "    count = count_dict.get(number, 0)\n",
    "    total_count += count\n",
    "    average_pixel_value = pixel_sums_by_digit[number] / pixel_counts_by_digit[number] if pixel_counts_by_digit[number] > 0 else 0\n",
    "    print(f\"Dígito {number}: {count} ocorrências, valor médio dos pixels = {average_pixel_value:.2f}\")\n",
    "\n",
    "average_count = total_count / 10\n",
    "print(f\"Valor médio de ocorrências: {average_count:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eX5d6s4EJTf8"
   },
   "source": [
    "### Item b)\n",
    "\n",
    "Faça um histograma que mostre a distribuição dos valores dos píxeis para cada dígito. Há muitos valores que são “apagados” (ou seja, com valor 0) ou a distribuição dos valores é mais equilibrada entre os dígitos?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bkOEzjdJVBB"
   },
   "outputs": [],
   "source": [
    "pixels_by_digit = {i: [] for i in range(10)}\n",
    "\n",
    "for img, label in zip(X_tot, y_tot):\n",
    "    flattened_img = img.flatten()  \n",
    "    pixels_by_digit[label].extend(flattened_img)\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8), sharey=True)\n",
    "fig.suptitle(\"Distribuição dos valores dos pixels para cada dígito (0 a 9)\", fontsize=16)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.hist(pixels_by_digit[i], bins=30, color=\"skyblue\", edgecolor=\"black\")\n",
    "    ax.set_title(f\"Dígito {i}\")\n",
    "    ax.set_xlim([0, 255]) \n",
    "    ax.set_xlabel(\"Valor do Pixel\")\n",
    "    ax.set_ylabel(\"Frequência\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Como pode ser visto, há muitos valores apagados, ou seja, com valor 0, isso é até mesmo fácil de identificar ao dar print em alguma listas de números, com isso, o valor médio dos pixels e deslocado à esquerda*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgl92AXbJR9B"
   },
   "source": [
    "### Item c)\n",
    "\n",
    "Crie uma imagem para cada dígito (de 0 a 9) em que cada píxel dessa nova imagem representa a média do valor dos píxeis para aquela classe. Você consegue reconhecer os dígitos nas imagens criadas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Para tanto, reutilizei os resultados de contagem e valor médio do item a, e também a função de apresentação das imagens, elas não ficaram tão nítidas, um pouco ruins, mas são reconhecíveis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hv4CKY55JVkx"
   },
   "outputs": [],
   "source": [
    "def show_images(images, title_texts):\n",
    "    cols = 3  \n",
    "    rows = int(len(images) / cols) + 1 \n",
    "    plt.figure(figsize=(12, 12))  \n",
    "    index = 1\n",
    "    for image, title_text in zip(images, title_texts):\n",
    "        plt.subplot(rows, cols, index)  \n",
    "        plt.axis('off') \n",
    "        plt.imshow(image, cmap=plt.cm.gray)  \n",
    "        plt.title(title_text, fontsize=15)  \n",
    "        index += 1\n",
    "    plt.tight_layout()  \n",
    "    plt.show()  \n",
    "\n",
    "pixel_sums_by_digit = {i: np.zeros_like(X_tot[0], dtype=float) for i in range(10)}\n",
    "counts_by_digit = {i: 0 for i in range(10)}\n",
    "\n",
    "for img, label in zip(X_tot, y_tot):\n",
    "    pixel_sums_by_digit[label] += img\n",
    "    counts_by_digit[label] += 1\n",
    "\n",
    "average_images = []\n",
    "titles = []\n",
    "for digit in range(10):\n",
    "    if counts_by_digit[digit] > 0:\n",
    "        average_image = pixel_sums_by_digit[digit] / counts_by_digit[digit]\n",
    "        average_images.append(average_image)\n",
    "        titles.append(f\"Dígito {digit}\")\n",
    "    else:\n",
    "        print(f\"Aviso: Nenhuma imagem encontrada para o dígito {digit}\")\n",
    "\n",
    "show_images(average_images, titles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLzAAnAGHQYx"
   },
   "source": [
    "# Tarefa 03: Treinamento e Teste de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGx_wlftUhq_"
   },
   "source": [
    "### Item a)\n",
    "\n",
    "Treine a ANN1 com 784 entradas, 8 neurônios na 1⁠ª camada oculta, 8 neurônios na 2⁠ª camada oculta e 10 saídas. Utilize 5 épocas para o treinamento. Use a biblioteca `scikit-learn`:\n",
    "\n",
    "- Input Layer: 784 entradas (28x28);\n",
    "- Hidden Layer 1: 8 neurônios;\n",
    "- Hidden Layer 2: 8 neurônios;\n",
    "- Output Layer: 10 saídas; (Classificador 0-9)\n",
    "- Treine com 10 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-lDDeAfZPlK"
   },
   "outputs": [],
   "source": [
    "X_tot_vec = X_tot.reshape(-1, 28 * 28) / 255 # Dados transformados em um 1d array e depois normalizados\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tot_vec, y_tot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurado a estrutura da rede, basta, agora, realizar a validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann1 = MLPClassifier(hidden_layer_sizes=(8, 8), max_iter=10 , random_state=42)\n",
    "ann1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann1.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota-se que esta estrutura da rede, embora muito simples, conseguir resultados bastante interessantes, os próximos passos consideram novas redes, e alguns detalhes que vão melhorar o desempenho do modelo.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVaSP7OGXD2d"
   },
   "source": [
    "### Item b)\n",
    "\n",
    "Treine a ANN2 com 784 entradas, 256 neurônios na 1⁠ª camada oculta, 256 neurônios na 2⁠ª camada oculta, 256 neurônios na 3ª camada oculta, 256 neurônios na 4ª camada oculta e 10 saídas. Utilize 20 épocas dessa vez. Use a biblioteca `scikit-learn`.\n",
    "\n",
    "- Input Layer: 784 entradas (28x28);\n",
    "- Hidden Layer 1: 256 neurônios;\n",
    "- Hidden Layer 2: 256 neurônios;\n",
    "- Hidden Layer 3: 256 neurônios;\n",
    "- Hidden Layer 4: 256 neurônios;\n",
    "- Output Layer: 10 saídas; (Classificação 0-9)\n",
    "- Treine com 20 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psIhum9XZQBZ"
   },
   "outputs": [],
   "source": [
    "ann2 = MLPClassifier(hidden_layer_sizes=(256, 256, 256, 256), max_iter=20, random_state=42)\n",
    "ann2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann2.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota-se, agora, que os resultados estão quase perfeitos com o obtido. Nesse sentido, houve uma melhora significativa direta com o aumento do número de neurônios e de épocas de treinamento.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "me4UkIkmXCkJ"
   },
   "source": [
    "### Item c)\n",
    "\n",
    "Agora você treinará um novo modelo, mais adequado. Para isso, gere ao menos 5 configurações de redes neurais, variando o número de camadas ocultas, o número de neurônios e o número de épocas. As configurações devem estar intermediárias entre `[8, 8]` e `[256, 256, 256, 256]`.\n",
    "\n",
    "Utilize a função `GridSearchCV` para realizar uma busca exaustiva pelos hiperparâmetros e encontre a configuração que oferece o melhor classificador, justificando sua escolha com base nas métricas de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = [(64), (32, 64), (8, 32, 128), (32, 32, 32, 32), (128, 64, 128)] # Camadas ocultas dos 5 modelos\n",
    "epochs = [20] \n",
    "grid = {\"hidden_layer_sizes\" : hidden_layers,\n",
    "        \"max_iter\" : epochs,\n",
    "        \"random_state\" : [42],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = GridSearchCV(MLPClassifier(random_state=42),grid,cv=3,n_jobs = -1, scoring=\"accuracy\")\n",
    "\n",
    "grid_result.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dos modelos selecionados, o que apresentou melhores resultados foi o com parâmetros {grid_result.best_params_}.\\nEsse modelo teve como resultado uma acurácia de {grid_result.best_score_*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkOTVK9WXBHT"
   },
   "source": [
    "### Item d)\n",
    "\n",
    "Para os modelos treinados nas questões a) e b), além do classificador encontrado na questão c), compare o desempenho dos modelos, analisando se apresentam *underfitting* ou *overfitting*. Justifique com gráficos e análises.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3OZgkBJ2ZQ_p"
   },
   "outputs": [],
   "source": [
    "hidden_layers = (128, 64, 128) # Camadas ocultas\n",
    "epochs = 20 # épocas para serem realizadas\n",
    "\n",
    "ann3 = MLPClassifier(hidden_layer_sizes=hidden_layers, max_iter=epochs, random_state=42)\n",
    "ann3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(hl,epochs,model):\n",
    "    classes = np.unique(y_train)\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "\n",
    "\n",
    "\n",
    "    ANN = MLPClassifier(hidden_layer_sizes=hl, max_iter=1, warm_start=True, random_state=42)\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        ANN.partial_fit(X_train, y_train, classes=classes)\n",
    "        train_pred = ANN.predict(X_train)\n",
    "        test_pred = ANN.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_train, train_pred)\n",
    "        acc_test = accuracy_score(y_test, test_pred)\n",
    "\n",
    "        train_accuracy.append(acc)\n",
    "        test_accuracy.append(acc_test)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, epochs + 1), train_accuracy, marker='o', label=\"Train Accuracy\")\n",
    "    plt.plot(range(1, epochs + 1), test_accuracy, marker='o', label=\"Test Accuracy\")\n",
    "    plt.title(f\"Acurácia com o passar das épocas (ANN{model})\")\n",
    "    plt.xlabel(\"Época\")\n",
    "    plt.ylabel(\"Acurácia\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losscurve(hl, epochs, model):\n",
    "    ANN = MLPClassifier(hidden_layer_sizes=hl, max_iter=1, warm_start=True, random_state=42)\n",
    "    ANN_test_loss = []\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        ANN.fit(X_train, y_train)\n",
    "        ANN_test_loss.append(log_loss(y_test, ANN.predict_proba(X_test)))\n",
    "        \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(ANN.loss_curve_, marker='*', label=f\"ANN{model} Train Loss\")\n",
    "    plt.plot(ANN_test_loss, marker='o', linestyle='--', label=f\"ANN{model} Test Loss\")\n",
    "    plt.title(f\"Loss Curve (ANN{model})\")\n",
    "    plt.xlabel(\"Iteração\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning((8,8),10,1) #ANN1\n",
    "learning((256,256,256,256),20,2) #ANN2\n",
    "learning((128,64,128),20,3) #ANN3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota-se, pelos gráficos que, quanto mais distante uma curva da outra, maior a tendência de overfitting. Ou seja, em ambos os casos, percebe-se que, à medida que a rede vai ser ajustando melhor, com mais épocas, mais distantes as curvas ficam, porém, com uma margem de diferença muito pequena, vale, também visualizar a evolução da taxa de erro, comumente chamada de curva de aprendizado.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losscurve((8,8),10,1) #ANN1\n",
    "losscurve((256,256,256,256),20,2) #ANN2\n",
    "losscurve((128,64,128),20,3) #ANN3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A interpretação é análoga em linhas gerais: o primeiro modelo aparenta menor tendência a overfitting, contudo, não atinge valores de acurácia tão elevados quanto os demais.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3twj4RlHQok"
   },
   "source": [
    "# Tarefa 04: Resultados e Visualizações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOOBIO28ZK1m"
   },
   "source": [
    "### Item a)\n",
    "\n",
    "Gere e apresente uma matriz de confusão que mostre a distribuição das previsões do melhor modelo. Quais as métricas de Acurácia, Precisão, Recall e F1-Score para esse modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wF88di0pZR3K"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\nResultados para {model_name}:\\n\", classification_report(y_test, y_pred))\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Acurácia para {model_name}: {accuracy:.2f}\")\n",
    "    cm = confusion_matrix(y_test,y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Previsto')\n",
    "    plt.ylabel('Real')\n",
    "    plt.title('Matriz de Confusão')\n",
    "    plt.show()\n",
    "    \n",
    "evaluate_model(ann3, X_test, y_test, 'ANN3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQ1EnPzLZJv1"
   },
   "source": [
    "### Item b)\n",
    "\n",
    "Exiba gráficos que mostram a evolução da acurácia e da perda (`Loss`) durante o treinamento do melhor modelo encontrado no item 3c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drg2DaDCZSP7"
   },
   "outputs": [],
   "source": [
    "def accuracy_loss(hl,epochs,model):\n",
    "    classes = np.unique(y_train)\n",
    "    train_accuracy = []\n",
    "    ANN = MLPClassifier(hidden_layer_sizes=hl, max_iter=1, warm_start=True, random_state=42)\n",
    "    for _ in range(epochs):\n",
    "        ANN.partial_fit(X_train, y_train, classes=classes)\n",
    "        train_pred = ANN.predict(X_train)\n",
    "        acc = accuracy_score(y_train, train_pred)\n",
    "        train_accuracy.append(acc)\n",
    "        \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, epochs + 1), train_accuracy, marker='o', label=\"Train Accuracy\")\n",
    "    plt.title(f\"Acurácia durante o treinamento (ANN{model})\")\n",
    "    plt.xlabel(\"Época\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(ANN.loss_curve_, marker='o', label=\"Train Loss\",color=\"orange\")\n",
    "    plt.title(f\"Perda durante o treinamento (ANN{model})\")\n",
    "    plt.xlabel(\"Iteração\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, epochs + 1), train_accuracy, marker='o', label=\"Train Accuracy\")\n",
    "    plt.plot(ANN.loss_curve_, marker='o', label=\"Train Loss\")\n",
    "    plt.title(f\"Acurácia e perda durante o treinamento (ANN{model})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "accuracy_loss((128,64,128),20,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvHuhj41ZIem"
   },
   "source": [
    "### Item c)\n",
    "\n",
    "Escolha algumas imagens do conjunto de teste e mostre previsões do seu modelo, com acertos e erros. Discuta quais fatores podem ter contribuído para essas previsões corretas e incorretas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yTDoZCiBZSvI"
   },
   "outputs": [],
   "source": [
    "y_pred = ann3.predict(X_test)\n",
    "previsao = y_pred == y_test # False = imagem rotulada errada\n",
    "previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = (128, 64, 128) # Camadas ocultas\n",
    "epochs = 20 # épocas para serem realizadas\n",
    "# Treinamento do modelo final com todos os dados e os parâmetros do melhor encontrado\n",
    "\n",
    "ANNF = MLPClassifier(hidden_layer_sizes=hidden_layers, max_iter=epochs, random_state=42)\n",
    "ANNF.fit(X_tot.reshape(-1,28 * 28) / 255, y_tot)\n",
    "# Saida do programa\n",
    "\n",
    "output = ANNF.predict(X_val.reshape(-1,28 * 28) / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'ID': np.arange(1,10001), 'Answer':output})\n",
    "df.set_index(\"ID\", inplace=True)\n",
    "df.to_csv('submission.csv')\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
